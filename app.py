import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import random
from datetime import datetime, timedelta
import json

# Page config
st.set_page_config(
    page_title="10kinthebag - TikTok TechJam 2025",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for modern UI
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    
    .policy-violation {
        background: linear-gradient(135deg, #ff6b6b, #ee5a24);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    
    .quality-score {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
    }
    
    .high-quality { color: #2ecc71; }
    .medium-quality { color: #f39c12; }
    .low-quality { color: #e74c3c; }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        border-radius: 10px;
        padding-left: 20px;
        padding-right: 20px;
    }
    
    .demo-section {
        background: #f8f9fa;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Load the actual dataset
@st.cache_data
def load_reviews_data():
    """Load and cache the reviews dataset"""
    try:
        df = pd.read_csv('reviews_cleaned.csv')
        return df
    except FileNotFoundError:
        st.error("‚ùå reviews_cleaned.csv not found! Please ensure the file is in the same directory as this script.")
        return None
    except Exception as e:
        st.error(f"‚ùå Error loading data: {str(e)}")
        return None

# Initialize session state
if 'demo_results' not in st.session_state:
    st.session_state.demo_results = []
if 'total_processed' not in st.session_state:
    st.session_state.total_processed = 0
if 'reviews_df' not in st.session_state:
    st.session_state.reviews_df = load_reviews_data()

# Mock ML Model Functions
def analyze_review_quality(review_text):
    """Mock function to simulate ML model prediction"""
    # Simulate processing time
    time.sleep(0.5)
    
    # Mock scoring based on text characteristics
    words = review_text.lower().split()
    score = 85  # Base score
    
    # Quality indicators
    if len(words) < 3:
        score -= 30
    elif len(words) > 50:
        score += 10
        
    # Policy violation checks
    violations = []
    
    # Advertisement detection
    ad_keywords = ['visit', 'www.', '.com', 'discount', 'promo', 'best deal']
    if any(keyword in review_text.lower() for keyword in ad_keywords):
        violations.append("Advertisement")
        score -= 25
    
    # Irrelevant content detection
    irrelevant_keywords = ['phone', 'laptop', 'car', 'movie', 'song']
    if any(keyword in review_text.lower() for keyword in irrelevant_keywords):
        violations.append("Irrelevant Content")
        score -= 20
    
    # Rant without visit detection
    rant_keywords = ['never been', 'heard it', 'terrible', 'worst ever']
    if any(keyword in review_text.lower() for keyword in rant_keywords):
        violations.append("Rant Without Visit")
        score -= 35
    
    # Ensure score bounds
    score = max(0, min(100, score + random.randint(-5, 15)))
    
    return score, violations

def get_quality_category(score):
    if score >= 80:
        return "High Quality", "high-quality"
    elif score >= 60:
        return "Medium Quality", "medium-quality"
    else:
        return "Low Quality", "low-quality"

# Header
st.markdown("""
<div class="main-header">
    <h1>üõ°Ô∏è 10kinthebag</h1>
    <h3>Intelligent Review Quality Assessment System</h3>
    <p>TikTok TechJam 2025 ‚Ä¢ Powered by Advanced ML & NLP</p>
</div>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown("## üéØ Navigation")
    page = st.selectbox(
        "Choose Demo Mode:",
        ["üè† Dashboard", "üîç Live Analysis", "üìä Batch Processing", "üìà Analytics"]
    )
    
    st.markdown("---")
    st.markdown("## ‚öôÔ∏è Model Settings")
    confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.75)
    strict_mode = st.checkbox("Strict Policy Enforcement", value=True)
    
    st.markdown("---")
    st.markdown("## üìã Policy Categories")
    st.markdown("""
    - üö´ **Advertisement**: Promotional content
    - ‚ùå **Irrelevant**: Off-topic reviews  
    - üò§ **Rant w/o Visit**: Complaints without visiting
    """)

if page == "üè† Dashboard":
    # Check if data is loaded
    if st.session_state.reviews_df is None:
        st.error("‚ùå Cannot load dashboard without reviews data. Please ensure reviews_cleaned.csv is available.")
        st.stop()
    
    df = st.session_state.reviews_df
    
    # Dashboard Overview with real data
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="üìä Reviews Available",
            value=f"{len(df):,}",
            delta=f"{len(df) - 10000:,} in dataset"
        )
    
    with col2:
        # Calculate average rating if rating column exists
        avg_rating = df['rating'].mean() if 'rating' in df.columns else 4.2
        st.metric(
            label="‚≠ê Average Rating",
            value=f"{avg_rating:.1f}",
            delta="0.2 vs last month"
        )
    
    with col3:
        # Estimate violations from actual data
        estimated_violations = len(df) // 10  # Mock estimation
        st.metric(
            label="üö® Estimated Violations",
            value=f"{estimated_violations:,}",
            delta="-15% this week"
        )
    
    with col4:
        st.metric(
            label="‚ö° Model Accuracy",
            value="94.2%",
            delta="2.1% improved"
        )
    
    # Charts with real data
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìà Review Length Distribution")
        
        # Calculate review lengths from actual data
        if 'review_text' in df.columns or 'text' in df.columns:
            text_col = 'review_text' if 'review_text' in df.columns else 'text'
            df['review_length'] = df[text_col].astype(str).str.len()
            
            # Create length categories
            df['length_category'] = pd.cut(
                df['review_length'], 
                bins=[0, 50, 150, 500, float('inf')], 
                labels=['Very Short', 'Short', 'Medium', 'Long']
            )
            
            length_counts = df['length_category'].value_counts()
            
            fig = px.pie(
                values=length_counts.values,
                names=length_counts.index,
                color_discrete_sequence=['#e74c3c', '#f39c12', '#2ecc71', '#3498db'],
                hole=0.4
            )
            fig.update_layout(height=400, title="Review Length Distribution")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No text column found for analysis")
    
    with col2:
        st.markdown("### ‚≠ê Rating Distribution")
        
        if 'rating' in df.columns:
            rating_counts = df['rating'].value_counts().sort_index()
            
            fig = px.bar(
                x=rating_counts.index,
                y=rating_counts.values,
                color=rating_counts.values,
                color_continuous_scale='RdYlGn',
                labels={'x': 'Star Rating', 'y': 'Number of Reviews'}
            )
            fig.update_layout(height=400, title="Star Rating Distribution")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("No rating column found in dataset")
    
    # Data insights section
    st.markdown("### üìã Dataset Overview")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### üìä Data Summary")
        
        # Display actual data info
        st.write(f"**Total Reviews:** {len(df):,}")
        st.write(f"**Columns Available:** {', '.join(df.columns)}")
        
        if 'rating' in df.columns:
            st.write(f"**Rating Range:** {df['rating'].min():.1f} - {df['rating'].max():.1f}")
        
        # Show data types
        st.markdown("**Column Information:**")
        for col in df.columns[:6]:  # Show first 6 columns
            dtype = str(df[col].dtype)
            null_count = df[col].isnull().sum()
            st.write(f"‚Ä¢ **{col}**: {dtype} ({null_count} nulls)")
    
    with col2:
        st.markdown("#### üîç Sample Reviews")
        
        # Show actual sample reviews
        text_col = None
        for col_name in ['review_text', 'text', 'content', 'review']:
            if col_name in df.columns:
                text_col = col_name
                break
        
        if text_col:
            sample_reviews = df[text_col].dropna().sample(min(3, len(df))).tolist()
            for i, review in enumerate(sample_reviews):
                truncated = review[:100] + "..." if len(review) > 100 else review
                st.markdown(f"**Sample {i+1}:** {truncated}")
        else:
            st.warning("No text column found for preview")

elif page == "üîç Live Analysis":
    if st.session_state.reviews_df is None:
        st.error("‚ùå Cannot perform analysis without reviews data.")
        st.stop()
    
    df = st.session_state.reviews_df
    
    st.markdown("## üîç Live Review Analysis")
    st.markdown("Test our AI model with reviews from your actual dataset!")
    
    # Get text column name
    text_col = None
    for col_name in ['review_text', 'text', 'content', 'review']:
        if col_name in df.columns:
            text_col = col_name
            break
    
    if text_col is None:
        st.error("‚ùå No text column found in dataset. Expected columns: review_text, text, content, or review")
        st.stop()
    
    # Sample reviews from actual data for quick testing
    sample_reviews = df[text_col].dropna().sample(min(5, len(df))).tolist()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ‚úçÔ∏è Enter Review Text")
        
        # Quick sample buttons from real data
        st.markdown("**üìù Sample Reviews from Your Dataset:**")
        cols = st.columns(min(3, len(sample_reviews)))
        for i, (col, sample) in enumerate(zip(cols, sample_reviews[:3])):
            with col:
                truncated_sample = sample[:40] + "..." if len(sample) > 40 else sample
                if st.button(f"üìÑ Sample {i+1}", key=f"sample_{i}", help=sample):
                    st.session_state.review_input = sample
        
        review_text = st.text_area(
            "Review Text:",
            value=st.session_state.get('review_input', ''),
            height=150,
            placeholder="Enter a review to analyze or click a sample above..."
        )
        
        # Additional metadata inputs
        col1_meta, col2_meta = st.columns(2)
        with col1_meta:
            location_type = st.selectbox("Location Type", ["Restaurant", "Hotel", "Shop", "Service", "Other"])
            reviewer_history = st.number_input("Reviewer's Total Reviews", min_value=0, value=23)
        
        with col2_meta:
            review_date = st.date_input("Review Date", value=datetime.now())
            star_rating = st.slider("Star Rating", 1, 5, 4)
        
        # Random sample button
        if st.button("üé≤ Load Random Review from Dataset", use_container_width=True):
            random_review = df[text_col].dropna().sample(1).iloc[0]
            st.session_state.review_input = random_review
            st.rerun()
    
    with col2:
        st.markdown("### üéØ Analysis Results")
        
        if st.button("üî¨ Analyze Review", type="primary", use_container_width=True):
            if review_text.strip():
                with st.spinner("ü§ñ AI is analyzing the review..."):
                    score, violations = analyze_review_quality(review_text)
                    quality_cat, quality_class = get_quality_category(score)
                    
                    # Store result
                    result = {
                        'text': review_text[:100] + "..." if len(review_text) > 100 else review_text,
                        'score': score,
                        'quality': quality_cat,
                        'violations': violations,
                        'timestamp': datetime.now()
                    }
                    st.session_state.demo_results.append(result)
                    st.session_state.total_processed += 1
                
                # Display results
                st.markdown(f"""
                <div class="metric-card">
                    <div class="quality-score {quality_class}">{score}</div>
                    <p style="text-align: center; margin-top: 0;"><strong>{quality_cat}</strong></p>
                </div>
                """, unsafe_allow_html=True)
                
                # Policy violations
                if violations:
                    st.markdown("**üö® Policy Violations Detected:**")
                    for violation in violations:
                        st.markdown(f"""
                        <div class="policy-violation">
                            ‚ö†Ô∏è <strong>{violation}</strong>
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.success("‚úÖ No policy violations detected!")
                
                # Confidence bars
                st.markdown("**üìä Confidence Breakdown:**")
                confidence_data = {
                    'Quality': random.uniform(0.8, 0.95),
                    'Relevancy': random.uniform(0.75, 0.92),
                    'Authenticity': random.uniform(0.70, 0.88)
                }
                
                for metric, conf in confidence_data.items():
                    st.progress(conf, text=f"{metric}: {conf:.1%}")
            
            else:
                st.warning("Please enter a review to analyze!")
    
    # Dataset statistics sidebar
    with st.sidebar:
        if df is not None:
            st.markdown("### üìä Dataset Statistics")
            st.write(f"**Total Reviews:** {len(df):,}")
            
            if 'rating' in df.columns:
                st.write(f"**Avg Rating:** {df['rating'].mean():.1f}")
                st.write(f"**Rating Range:** {df['rating'].min()}-{df['rating'].max()}")
            
            # Show column info
            st.markdown("**Available Columns:**")
            for col in df.columns[:5]:  # Show first 5 columns
                null_pct = (df[col].isnull().sum() / len(df) * 100)
                st.write(f"‚Ä¢ {col} ({null_pct:.1f}% null)")
    
    # Recent analysis history
    if st.session_state.demo_results:
        st.markdown("---")
        st.markdown("### üìù Recent Analysis History")
        
        for i, result in enumerate(reversed(st.session_state.demo_results[-5:])):
            with st.expander(f"Analysis #{len(st.session_state.demo_results)-i} - Score: {result['score']}"):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"**Review:** {result['text']}")
                    if result['violations']:
                        st.write(f"**Violations:** {', '.join(result['violations'])}")
                with col2:
                    quality_cat, quality_class = get_quality_category(result['score'])
                    st.markdown(f"<div class='quality-score {quality_class}'>{result['score']}</div>", unsafe_allow_html=True)

elif page == "üìä Batch Processing":
    st.markdown("## üìä Batch Review Processing")
    
    if st.session_state.reviews_df is None:
        st.error("‚ùå Cannot perform batch processing without reviews data.")
        st.stop()
    
    df = st.session_state.reviews_df
    
    # Show dataset info
    st.markdown("### üìã Your Dataset Information")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Reviews", f"{len(df):,}")
    with col2:
        st.metric("Total Columns", len(df.columns))
    with col3:
        text_col = None
        for col_name in ['review_text', 'text', 'content', 'review']:
            if col_name in df.columns:
                text_col = col_name
                break
        st.metric("Text Column", text_col if text_col else "‚ùå Not Found")
    
    if text_col is None:
        st.error("‚ùå No suitable text column found. Please ensure your CSV has a column named 'review_text', 'text', 'content', or 'review'.")
        st.stop()
    
    # Data preview
    with st.expander("üìã Dataset Preview"):
        st.dataframe(df.head(10), use_container_width=True)
    
    # Processing options
    st.markdown("### ‚öôÔ∏è Processing Configuration")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        process_limit = st.number_input(
            "Reviews to process:", 
            min_value=1, 
            max_value=len(df), 
            value=min(50, len(df)),
            help="Start small for demo purposes"
        )
    
    with col2:
        show_violations_only = st.checkbox("Show only violations", value=False)
        sample_randomly = st.checkbox("Random sampling", value=True)
    
    with col3:
        # Column selection
        rating_column = st.selectbox(
            "Rating column:", 
            ["None"] + [col for col in df.columns if col != text_col], 
            key="rating_col"
        )
        location_column = st.selectbox(
            "Location column:", 
            ["None"] + [col for col in df.columns if col != text_col], 
            key="location_col"
        )
    
    # Process button
    if st.button("üöÄ Process Reviews from Dataset", type="primary", use_container_width=True):
        # Get sample data
        if sample_randomly:
            sample_df = df.sample(n=process_limit, random_state=42)
        else:
            sample_df = df.head(process_limit)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results = []
        
        for idx, (_, row) in enumerate(sample_df.iterrows()):
            # Update progress
            progress = (idx + 1) / len(sample_df)
            progress_bar.progress(progress)
            status_text.text(f"Processing review {idx + 1}/{len(sample_df)}...")
            
            # Analyze review
            review_text = str(row[text_col])
            score, violations = analyze_review_quality(review_text)
            quality_cat, _ = get_quality_category(score)
            
            result = {
                'Review_ID': idx + 1,
                'Review_Text': review_text[:100] + "..." if len(review_text) > 100 else review_text,
                'Quality_Score': score,
                'Quality_Category': quality_cat,
                'Policy_Violations': ', '.join(violations) if violations else 'None',
                'Violation_Count': len(violations)
            }
            
            # Add additional columns if they exist
            if rating_column != "None" and rating_column in df.columns:
                result['Original_Rating'] = row[rating_column]
            
            if location_column != "None" and location_column in df.columns:
                result['Location'] = str(row[location_column])[:50]
            
            results.append(result)
            
            # Small delay to show progress
            time.sleep(0.1)
        
        status_text.text("‚úÖ Processing complete!")
        progress_bar.progress(1.0)
        
        # Create results dataframe
        results_df = pd.DataFrame(results)
        
        # Filter if needed
        if show_violations_only:
            results_df = results_df[results_df['Violation_Count'] > 0]
            if len(results_df) == 0:
                st.warning("No violations found in the processed reviews!")
                results_df = pd.DataFrame(results)  # Show all results
        
        # Results summary
        st.markdown("### üìà Processing Results")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Processed", len(results))
        with col2:
            violations_count = len([r for r in results if r['Violation_Count'] > 0])
            st.metric("Violations Found", violations_count)
        with col3:
            avg_score = np.mean([r['Quality_Score'] for r in results])
            st.metric("Average Quality", f"{avg_score:.1f}")
        with col4:
            high_quality = len([r for r in results if r['Quality_Score'] >= 80])
            violation_rate = violations_count / len(results) * 100
            st.metric("Violation Rate", f"{violation_rate:.1f}%")
        
        # Results visualization
        col1, col2 = st.columns(2)
        
        with col1:
            # Quality distribution
            quality_dist = results_df['Quality_Category'].value_counts()
            fig = px.pie(
                values=quality_dist.values,
                names=quality_dist.index,
                title="Quality Distribution in Processed Batch",
                color_discrete_sequence=['#2ecc71', '#f39c12', '#e74c3c']
            )
            fig.update_layout(height=350)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Quality scores histogram
            fig = px.histogram(
                results_df,
                x='Quality_Score',
                nbins=20,
                title="Quality Score Distribution",
                color_discrete_sequence=['#3498db']
            )
            fig.update_layout(height=350)
            st.plotly_chart(fig, use_container_width=True)
        
        # Results table
        st.markdown("### üìã Detailed Results")
        
        # Color-code quality scores
        def color_quality_score(val):
            if val >= 80:
                return 'background-color: #d4edda'
            elif val >= 60:
                return 'background-color: #fff3cd'
            else:
                return 'background-color: #f8d7da'
        
        styled_df = results_df.style.applymap(color_quality_score, subset=['Quality_Score'])
        st.dataframe(styled_df, use_container_width=True, height=400)
        
        # Download button
        csv = results_df.to_csv(index=False)
        st.download_button(
            label="üì• Download Results CSV",
            data=csv,
            file_name=f"review_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
        # Additional insights
        if violations_count > 0:
            st.markdown("### üö® Violation Analysis")
            
            # Count violations by type
            all_violations = []
            for result in results:
                if result['Violation_Count'] > 0:
                    violations = result['Policy_Violations'].split(', ')
                    all_violations.extend(violations)
            
            if all_violations:
                violation_counts = pd.Series(all_violations).value_counts()
                
                fig = px.bar(
                    x=violation_counts.index,
                    y=violation_counts.values,
                    title="Policy Violation Types",
                    color=violation_counts.values,
                    color_continuous_scale="Reds"
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)(uploaded_file)
            
            st.success(f"‚úÖ Successfully loaded {len(df)} reviews!")
            
            # Data preview
            with st.expander("üìã Data Preview"):
                st.dataframe(df.head(10), use_container_width=True)
            
            # Column mapping
            st.markdown("### üéØ Column Mapping")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                text_column = st.selectbox("Review Text Column:", df.columns, key="text_col")
            with col2:
                rating_column = st.selectbox("Rating Column (optional):", ["None"] + list(df.columns), key="rating_col")
            with col3:
                location_column = st.selectbox("Location Column (optional):", ["None"] + list(df.columns), key="location_col")
            
            # Processing options
            st.markdown("### ‚öôÔ∏è Processing Options")
            col1, col2 = st.columns(2)
            
            with col1:
                process_limit = st.number_input("Max reviews to process:", min_value=1, max_value=len(df), value=min(100, len(df)))
            with col2:
                show_violations_only = st.checkbox("Show only policy violations", value=False)
            
            # Process button
            if st.button("üöÄ Process Reviews", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                status_text = st.empty()
                results_container = st.empty()
                
                results = []
                sample_df = df.head(process_limit)
                
                for idx, row in sample_df.iterrows():
                    # Update progress
                    progress = (idx + 1) / len(sample_df)
                    progress_bar.progress(progress)
                    status_text.text(f"Processing review {idx + 1}/{len(sample_df)}...")
                    
                    # Analyze review
                    review_text = str(row[text_column])
                    score, violations = analyze_review_quality(review_text)
                    quality_cat, _ = get_quality_category(score)
                    
                    result = {
                        'Review_ID': idx + 1,
                        'Review_Text': review_text[:100] + "..." if len(review_text) > 100 else review_text,
                        'Quality_Score': score,
                        'Quality_Category': quality_cat,
                        'Policy_Violations': ', '.join(violations) if violations else 'None',
                        'Violation_Count': len(violations)
                    }
                    results.append(result)
                
                # Create results dataframe
                results_df = pd.DataFrame(results)
                
                # Filter if needed
                if show_violations_only:
                    results_df = results_df[results_df['Violation_Count'] > 0]
                
                status_text.text("‚úÖ Processing complete!")
                progress_bar.progress(1.0)
                
                # Results summary
                st.markdown("### üìà Processing Results")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total Processed", len(results))
                with col2:
                    violations_count = len([r for r in results if r['Violation_Count'] > 0])
                    st.metric("Violations Found", violations_count)
                with col3:
                    avg_score = np.mean([r['Quality_Score'] for r in results])
                    st.metric("Average Quality", f"{avg_score:.1f}")
                with col4:
                    high_quality = len([r for r in results if r['Quality_Score'] >= 80])
                    st.metric("High Quality %", f"{(high_quality/len(results)*100):.1f}%")
                
                # Results table
                st.markdown("### üìã Detailed Results")
                
                # Color-code quality scores
                def color_quality_score(val):
                    if val >= 80:
                        return 'background-color: #d4edda'
                    elif val >= 60:
                        return 'background-color: #fff3cd'
                    else:
                        return 'background-color: #f8d7da'
                
                styled_df = results_df.style.applymap(color_quality_score, subset=['Quality_Score'])
                st.dataframe(styled_df, use_container_width=True, height=400)
                
                # Download button
                csv = results_df.to_csv(index=False)
                st.download_button(
                    label="üì• Download Results CSV",
                    data=csv,
                    file_name=f"review_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        


elif page == "üìà Analytics":
    st.markdown("## üìà Advanced Analytics Dashboard")
    
    # Generate mock analytics data
    np.random.seed(42)
    
    # Performance metrics over time
    dates = pd.date_range(end=datetime.now(), periods=30, freq='D')
    performance_data = pd.DataFrame({
        'Date': dates,
        'Accuracy': np.random.normal(0.92, 0.02, 30).clip(0.85, 0.98),
        'Precision': np.random.normal(0.89, 0.03, 30).clip(0.80, 0.95),
        'Recall': np.random.normal(0.87, 0.025, 30).clip(0.78, 0.94),
        'F1_Score': np.random.normal(0.88, 0.02, 30).clip(0.82, 0.94)
    })
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Model Performance Metrics")
        
        fig = go.Figure()
        
        metrics = ['Accuracy', 'Precision', 'Recall', 'F1_Score']
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        
        for metric, color in zip(metrics, colors):
            fig.add_trace(go.Scatter(
                x=performance_data['Date'],
                y=performance_data[metric],
                mode='lines+markers',
                name=metric.replace('_', ' '),
                line=dict(color=color, width=3),
                marker=dict(size=6)
            ))
        
        fig.update_layout(
            height=400,
            xaxis_title="Date",
            yaxis_title="Score",
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### üéØ Violation Type Distribution")
        
        violation_data = pd.DataFrame({
            'Violation_Type': ['Advertisement', 'Irrelevant Content', 'Rant Without Visit', 'Multiple Violations'],
            'Count': [324, 567, 198, 114],
            'Severity': ['High', 'Medium', 'High', 'Critical']
        })
        
        fig = px.bar(
            violation_data,
            x='Violation_Type',
            y='Count',
            color='Severity',
            color_discrete_map={
                'Critical': '#8e44ad',
                'High': '#e74c3c',
                'Medium': '#f39c12',
                'Low': '#27ae60'
            }
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # Confusion matrix and advanced metrics
    st.markdown("### üéØ Model Performance Analysis")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**üéØ Classification Accuracy**")
        # Mock confusion matrix data
        confusion_data = np.array([[456, 23, 12], [18, 334, 28], [7, 15, 203]])
        labels = ['High Quality', 'Medium Quality', 'Low Quality']
        
        fig = px.imshow(
            confusion_data,
            labels=dict(x="Predicted", y="Actual"),
            x=labels,
            y=labels,
            color_continuous_scale="Blues",
            text_auto=True
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("**‚ö° Processing Speed**")
        speed_data = pd.DataFrame({
            'Batch_Size': [10, 50, 100, 500, 1000],
            'Processing_Time': [0.8, 2.1, 3.9, 18.2, 35.7]
        })
        
        fig = px.line(
            speed_data,
            x='Batch_Size',
            y='Processing_Time',
            markers=True,
            title="Processing Time vs Batch Size"
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    with col3:
        st.markdown("**üåç Geographic Distribution**")
        geo_data = pd.DataFrame({
            'Region': ['North America', 'Europe', 'Asia Pacific', 'Others'],
            'Reviews': [4500, 3200, 3800, 1347],
            'Avg_Quality': [78.5, 82.1, 76.3, 79.8]
        })
        
        fig = px.scatter(
            geo_data,
            x='Reviews',
            y='Avg_Quality',
            size='Reviews',
            color='Region',
            hover_name='Region'
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)

else:  # Analytics page
    st.markdown("## üìà Advanced Analytics Dashboard")
    
    if st.session_state.reviews_df is None:
        st.error("‚ùå Cannot show analytics without reviews data.")
        st.stop()
    
    df = st.session_state.reviews_df
    
    # Real data analytics
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Dataset Analytics")
        
        # Text column analysis
        text_col = None
        for col_name in ['review_text', 'text', 'content', 'review']:
            if col_name in df.columns:
                text_col = col_name
                break
        
        if text_col:
            # Calculate real text statistics
            df['word_count'] = df[text_col].astype(str).str.split().str.len()
            df['char_count'] = df[text_col].astype(str).str.len()
            
            # Word count distribution
            fig = px.histogram(
                df,
                x='word_count',
                nbins=30,
                title="Word Count Distribution",
                color_discrete_sequence=['#3498db']
            )
            fig.update_layout(height=350)
            st.plotly_chart(fig, use_container_width=True)
            
            # Statistics
            st.markdown("**üìä Text Statistics:**")
            st.write(f"‚Ä¢ **Average words per review:** {df['word_count'].mean():.1f}")
            st.write(f"‚Ä¢ **Median words per review:** {df['word_count'].median():.1f}")
            st.write(f"‚Ä¢ **Longest review:** {df['word_count'].max()} words")
            st.write(f"‚Ä¢ **Shortest review:** {df['word_count'].min()} words")
        else:
            st.warning("No text column found for analysis")
    
    with col2:
        st.markdown("### ‚≠ê Rating Analysis")
        
        if 'rating' in df.columns:
            # Rating distribution
            rating_counts = df['rating'].value_counts().sort_index()
            
            fig = px.bar(
                x=rating_counts.index,
                y=rating_counts.values,
                color=rating_counts.values,
                color_continuous_scale='RdYlGn',
                title="Actual Rating Distribution",
                labels={'x': 'Star Rating', 'y': 'Number of Reviews'}
            )
            fig.update_layout(height=350)
            st.plotly_chart(fig, use_container_width=True)
            
            # Rating statistics
            st.markdown("**‚≠ê Rating Statistics:**")
            st.write(f"‚Ä¢ **Average rating:** {df['rating'].mean():.2f}")
            st.write(f"‚Ä¢ **Median rating:** {df['rating'].median():.1f}")
            st.write(f"‚Ä¢ **Most common rating:** {df['rating'].mode().iloc[0]}")
            st.write(f"‚Ä¢ **Rating standard deviation:** {df['rating'].std():.2f}")
            
        else:
            st.warning("No rating column found in dataset")
    
    # Advanced analytics
    st.markdown("### üî¨ Advanced Text Analysis")
    
    if text_col:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**üìè Review Length Categories**")
            
            # Create length categories based on actual data
            df['length_category'] = pd.cut(
                df['char_count'], 
                bins=[0, 50, 200, 500, float('inf')], 
                labels=['Very Short', 'Short', 'Medium', 'Long']
            )
            
            length_dist = df['length_category'].value_counts()
            
            for category, count in length_dist.items():
                percentage = (count / len(df)) * 100
                st.write(f"‚Ä¢ **{category}:** {count:,} ({percentage:.1f}%)")
        
        with col2:
            st.markdown("**üî§ Common Words Analysis**")
            
            # Basic word analysis from actual reviews
            all_text = ' '.join(df[text_col].dropna().astype(str).str.lower())
            words = all_text.split()
            
            # Filter out common stop words
            stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'was', 'are', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'}
            filtered_words = [word for word in words if word not in stop_words and len(word) > 3]
            
            if filtered_words:
                word_freq = pd.Series(filtered_words).value_counts().head(8)
                for word, freq in word_freq.items():
                    st.write(f"‚Ä¢ **{word.title()}:** {freq}")
        
        with col3:
            st.markdown("**üìä Quality Indicators**")
            
            # Analyze potential quality indicators from actual data
            df['has_exclamation'] = df[text_col].astype(str).str.contains('!').sum()
            df['has_question'] = df[text_col].astype(str).str.contains('\?').sum()
            df['all_caps_words'] = df[text_col].astype(str).str.count(r'\b[A-Z]{2,}\b')
            
            st.write(f"‚Ä¢ **Reviews with exclamations:** {df['has_exclamation']}")
            st.write(f"‚Ä¢ **Reviews with questions:** {df['has_question']}")
            st.write(f"‚Ä¢ **Average caps words:** {df['all_caps_words'].mean():.1f}")
            
            # Potential spam indicators
            df['has_url'] = df[text_col].astype(str).str.contains(r'www\.|\.com|http').sum()
            st.write(f"‚Ä¢ **Reviews with URLs:** {df['has_url']}")
    
    # Sample processing demonstration
    st.markdown("---")
    st.markdown("### üéØ Live Processing Preview")
    
    if st.button("üîÑ Process Random Sample (Live Demo)", use_container_width=True):
        # Take a small random sample for live demo
        sample_size = min(10, len(df))
        demo_sample = df.sample(n=sample_size, random_state=np.random.randint(1000))
        
        results = []
        progress_container = st.container()
        
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (_, row) in enumerate(demo_sample.iterrows()):
                progress = (idx + 1) / sample_size
                progress_bar.progress(progress)
                status_text.text(f"üî¨ Analyzing review {idx + 1}/{sample_size}...")
                
                review_text = str(row[text_col])
                score, violations = analyze_review_quality(review_text)
                quality_cat, _ = get_quality_category(score)
                
                results.append({
                    'Review': review_text[:80] + "..." if len(review_text) > 80 else review_text,
                    'Quality_Score': score,
                    'Quality': quality_cat,
                    'Violations': ', '.join(violations) if violations else 'None',
                    'Original_Rating': row['rating'] if 'rating' in df.columns else 'N/A'
                })
                
                time.sleep(0.3)  # Demo delay
            
            status_text.success("‚úÖ Live demo complete!")
            progress_bar.progress(1.0)
        
        # Show results
        results_df = pd.DataFrame(results)
        st.dataframe(results_df, use_container_width=True)
        
        # Quick stats
        avg_quality = results_df['Quality_Score'].mean()
        violation_count = len([r for r in results if r['Violations'] != 'None'])
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Sample Avg Quality", f"{avg_quality:.1f}")
        with col2:
            st.metric("Violations Found", violation_count)
        with col3:
            st.metric("Clean Reviews", len(results) - violation_count)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üö® Active Policy Rules**")
            policies = [
                ("Advertisement Detection", "‚úÖ Active", "#2ecc71"),
                ("Irrelevant Content Filter", "‚úÖ Active", "#2ecc71"),
                ("Rant Detection", "‚úÖ Active", "#2ecc71"),
                ("Spam Prevention", "‚úÖ Active", "#2ecc71"),
                ("Language Quality Check", "‚ö†Ô∏è Beta", "#f39c12")
            ]
            
            for policy, status, color in policies:
                st.markdown(f"""
                <div style="padding: 0.5rem; border-left: 4px solid {color}; margin: 0.5rem 0; background: #f8f9fa;">
                    <strong>{policy}</strong><br>
                    <span style="color: {color};">{status}</span>
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("**üìä Policy Violation Trends**")
            
            # Mini trend chart
            violation_trend = pd.DataFrame({
                'Day': list(range(1, 8)),
                'Violations': [45, 38, 52, 31, 29, 41, 33]
            })
            
            fig = px.line(
                violation_trend,
                x='Day',
                y='Violations',
                markers=True,
                title="Last 7 Days"
            )
            fig.update_layout(height=250, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)

# Footer
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    ### üöÄ **About ReviewGuard AI**
    Advanced ML system for automated review quality assessment, built for TikTok TechJam 2024.
    """)

with col2:
    st.markdown("""
    ### ‚öôÔ∏è **Technology Stack**
    - **Models**: Transformers, BERT, Custom NLP
    - **Backend**: Python, Streamlit
    - **ML**: scikit-learn, PyTorch, Hugging Face
    """)

with col3:
    st.markdown("""
    ### üèÜ **Key Features**
    - Real-time analysis
    - Policy enforcement
    - Batch processing
    - Interactive dashboard
    """)

# Live demo simulation in sidebar
with st.sidebar:
    if st.session_state.reviews_df is not None:
        st.markdown("### üéØ Quick Dataset Info")
        df = st.session_state.reviews_df
        
        st.write(f"**üìä Reviews loaded:** {len(df):,}")
        
        # Show available columns
        st.markdown("**üìã Available columns:**")
        for col in df.columns[:5]:
            st.write(f"‚Ä¢ {col}")
        if len(df.columns) > 5:
            st.write(f"‚Ä¢ ... and {len(df.columns) - 5} more")
        
        # Quick random review button
        text_col = None
        for col_name in ['review_text', 'text', 'content', 'review']:
            if col_name in df.columns:
                text_col = col_name
                break
        
        if text_col and st.button("üé≤ Random Review Preview"):
            random_review = df[text_col].dropna().sample(1).iloc[0]
            st.text_area("Random Review:", value=random_review[:200], height=100, key="sidebar_preview")
    
    else:
        st.warning("‚ö†Ô∏è reviews_cleaned.csv not loaded")
    
    if st.button("üé≠ Simulate Live Processing"):
        if st.session_state.reviews_df is not None and text_col:
            placeholder = st.empty()
            sample_reviews = st.session_state.reviews_df[text_col].dropna().sample(min(5, len(st.session_state.reviews_df))).tolist()
            
            for i, review in enumerate(sample_reviews):
                score, violations = analyze_review_quality(review)
                
                with placeholder.container():
                    st.markdown(f"**Processing Review #{i+1}**")
                    st.text(review[:40] + "...")
                    st.progress((i+1)/5)
                    if violations:
                        st.error(f"Violations: {', '.join(violations)}")
                    else:
                        st.success(f"Quality Score: {score}")
                    
                    time.sleep(1)
            
            placeholder.success("‚úÖ Live processing demo complete!")
        else:
            st.error("No data available for simulation")

# Real-time metrics updater
if 'last_update' not in st.session_state:
    st.session_state.last_update = time.time()

# Update metrics every 30 seconds (simulated)
current_time = time.time()
if current_time - st.session_state.last_update > 30:
    st.session_state.last_update = current_time
    st.rerun()

# Add some final impressive touches
st.markdown("""
---
<div style="text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white;">
    <h3>üéØ Ready to Transform Review Quality Assessment?</h3>
    <p>ReviewGuard AI combines cutting-edge NLP with intelligent policy enforcement to deliver unparalleled review quality insights.</p>
    <p><strong>Built by Team [Your Team Name] ‚Ä¢ TikTok TechJam 2024</strong></p>
</div>
""", unsafe_allow_html=True)